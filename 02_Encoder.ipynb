{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24067806-25c7-49f9-aa5e-6938f7dcf12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "class Encoder(object):\n",
    "    '''\n",
    "    The nonlinear encoder class maps data nonlinearly to high dimensional space.\n",
    "    To do this task, it uses two randomly generated tensors:\n",
    "\n",
    "    :math:`B`. The `(dim, features)` sized random basis hypervectors, drawn\n",
    "    from a standard normal distribution\n",
    "    :math:`b`. An additional `(dim,)` sized base, drawn from a uniform\n",
    "    distribution between :math:`[0, 2\\pi]`.\n",
    "\n",
    "    The hypervector :math:`H \\in \\mathbb{R}^D` of :math:`X \\in \\mathbb{R}^f`\n",
    "    is:\n",
    "\n",
    "    .. math:: H_i = \\cos(X \\cdot B_i + b_i) \\sin(X \\cdot B_i)\n",
    "\n",
    "    Args:\n",
    "        features (int, > 0): Dimensionality of original data.\n",
    "\n",
    "        dim (int, > 0): Target dimension for output data.\n",
    "    '''\n",
    "    def __init__(self, features : int, dim : int = 4000):\n",
    "        self.dim = dim\n",
    "        self.features = features\n",
    "        self.basis = torch.randn(self.dim, self.features)\n",
    "        self.base = torch.empty(self.dim).uniform_(0.0, 2*math.pi)\n",
    "\n",
    "    def __call__(self, x : torch.Tensor):\n",
    "        '''\n",
    "        Encodes each data point in `x` to high dimensional space.\n",
    "        The encoded representation of the `(n?, features)` samples described\n",
    "        in :math:`x`, is the `(n?, dim)` matrix :math:`H`:\n",
    "\n",
    "        .. math:: H_{ij} = \\cos(x_i \\cdot B_j + b_j) \\sin(x_i \\cdot B_j)\n",
    "\n",
    "        Note:\n",
    "            This encoder is very sensitive to data preprocessing. Try\n",
    "            making input have unit norm (normalizing) or standarizing each\n",
    "            feature to have mean=0 and std=1/sqrt(features) (scaling).\n",
    "\n",
    "        Args:\n",
    "            x (:class:`torch.Tensor`): The original data points to encode. Must\n",
    "                have size `(n?, features)`.\n",
    "\n",
    "        Returns:\n",
    "            :class:`torch.Tensor`: The high dimensional representation of each\n",
    "            of the `n?` data points in x, which respects the equation given\n",
    "            above. It has size `(n?, dim)`.\n",
    "        '''\n",
    "\n",
    "        n = x.size(0)\n",
    "        bsize = math.ceil(0.01*n)\n",
    "        h = torch.empty(n, self.dim, device=x.device, dtype=x.dtype)\n",
    "        temp = torch.empty(bsize, self.dim, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        # we need batches to remove memory usage\n",
    "        for i in range(0, n, bsize):\n",
    "            torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
    "            torch.add(temp, self.base, out=h[i:i+bsize])\n",
    "            h[i:i+bsize].cos_().mul_(temp.sin_())\n",
    "        return h\n",
    "\n",
    "    def to(self, *args):\n",
    "        '''\n",
    "        Moves data to the device specified, e.g. cuda, cpu or changes\n",
    "        dtype of the data representation, e.g. half or double.\n",
    "        Because the internal data is saved as torch.tensor, the parameter\n",
    "        can be anything that torch accepts. The change is done in-place.\n",
    "\n",
    "        Args:\n",
    "            device (str or :class:`torch.torch.device`) Device to move data.\n",
    "\n",
    "        Returns:\n",
    "            :class:`Encoder`: self\n",
    "        '''\n",
    "\n",
    "        self.basis = self.basis.to(*args)\n",
    "        self.base = self.base.to(*args)\n",
    "        return self\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCI",
   "language": "python",
   "name": "uci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
