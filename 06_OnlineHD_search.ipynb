{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58372954-ce73-4390-b69f-685de771ba92",
   "metadata": {},
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6077085c-f26a-40cb-a360-a9584facde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import onlinehd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bf0b9-6024-4ffb-8db8-5f5e8b7ec743",
   "metadata": {},
   "source": [
    "### loads simple mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71632882-63e2-40c5-ae76-b3bb07e90dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    # fetches data\n",
    "    x, y = sklearn.datasets.fetch_openml('mnist_784', return_X_y=True)\n",
    "    x = x.astype(np.float)\n",
    "    y = y.astype(np.int)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # split and normalize\n",
    "    x, x_test, y, y_test = sklearn.model_selection.train_test_split(x, y)\n",
    "    scaler = sklearn.preprocessing.Normalizer().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).long()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "    return x, x_test, y, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bb9227-8de2-4cd1-9de8-791edfa239d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    }
   ],
   "source": [
    "# simple OnlineHD training\n",
    "\n",
    "print('Loading...')\n",
    "x, x_test, y, y_test = load()\n",
    "classes = y.unique().size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662eb8b-4ee8-4d8d-96cf-4eed1b3e56bc",
   "metadata": {},
   "source": [
    "### import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb76b29f-d8f4-4896-85ab-6a30770fb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x.size(1)\n",
    "model = onlinehd.OnlineHD(classes, features, dim=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c4619-8d3a-4b5f-b2f4-50a1da61130c",
   "metadata": {},
   "source": [
    "### model.fit(x, y, encoded=False, \n",
    "\n",
    "### batch_size=1024, one_pass_fit=True, bootstrap=1.0, lr=0.035, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4842d9a-1bed-4602-b23a-cc147c54d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self,\n",
    "        x : torch.Tensor,\n",
    "        y : torch.Tensor,\n",
    "        encoded : bool = False,\n",
    "        lr : float = 0.035,\n",
    "        epochs : int = 120,\n",
    "        batch_size : Union[int, None, float] = 1024,\n",
    "        one_pass_fit : bool = True,\n",
    "        bootstrap : Union[float, str] = 0.01):\n",
    "    '''\n",
    "    Starts learning process using datapoints `x` as input points and `y`\n",
    "    as their labels.\n",
    "\n",
    "    Args:\n",
    "        x (:class:`torch.Tensor`): Input data points. Must\n",
    "            have size `(n?, dim)` if `encoded=False`, otherwise must\n",
    "            have size `(n?, features)`.\n",
    "\n",
    "        encoded (bool): Specifies if input data is already encoded.\n",
    "\n",
    "        lr (float, > 0): Learning rate.\n",
    "\n",
    "        epochs (int, > 0): Max number of epochs allowed.\n",
    "\n",
    "        batch_size (int, > 0 and <= n?, or float, > 0 and <= 1, or None):\n",
    "            If int, the number of samples to use in each batch. If float,\n",
    "            the fraction of the samples to use in each batch. If none the\n",
    "            whole dataset will be used per epoch (same if used 1.0 or n?).\n",
    "\n",
    "        one_pass_fit (bool): Whether to use onepass learning process or not.\n",
    "            If true, iterative method will be used after one pass fit\n",
    "            anyways for the number of epochs specified.\n",
    "\n",
    "        bootstrap (float, > 0, <= 1 or 'single-per-class'): In order to\n",
    "            initialize class hypervectors, OnlineHD does naive accumulation\n",
    "            with a small fragment of data. This portion is determined by\n",
    "            this argument. If 'single-per-class' is used, a single datapoint\n",
    "            per class will be used as starting class hypervector.\n",
    "\n",
    "    Warning:\n",
    "        Using `one_pass_fit` is not advisable for very large data or\n",
    "        while using GPU. It is expected to see high memory usage using\n",
    "        this option and it does not benefit from paralellization.\n",
    "\n",
    "    Returns:\n",
    "        :class:`OnlineHD`: self\n",
    "    '''\n",
    "\n",
    "    h = x if encoded else self.encode(x)\n",
    "    if one_pass_fit:\n",
    "        self._one_pass_fit(h, y, lr, bootstrap)\n",
    "    self._iterative_fit(h, y, lr, epochs, batch_size)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93441bf2-86ba-43c6-bec9-08a72539d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping in the hyper-dimension \n",
    "h = x if encoded else self.encode(x)\n",
    "\n",
    "\n",
    "if one_pass_fit:\n",
    "    self._one_pass_fit(h, y, lr, bootstrap)\n",
    "    \n",
    "self._iterative_fit(h, y, lr, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd1e76-bf4e-40e1-9ae2-412bf8794190",
   "metadata": {},
   "source": [
    "### h : hyperdimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961a0e9a-ca5e-44ba-8aca-92e0decbeae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52500, 10000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.encoder(x)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf552168-53f3-4f2e-a078-bbba3af5aa66",
   "metadata": {},
   "source": [
    "## model._one_pass_fit(h, y, lr=0.035, bootstrap=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5beba68-b82e-4125-b791-4eb8ac7820fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = math.ceil(1*h.size(0))\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7f49db-93a7-4a8a-b329-4b29fd5b4f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-6.4814e-01, -4.8698e-01,  5.3794e-02,  ..., -4.0393e-01,\n",
       "           1.6991e-02, -3.8696e-01],\n",
       "         [ 1.0055e-01, -1.5533e-01,  3.6316e-01,  ..., -6.9401e-01,\n",
       "           7.5901e-01,  1.2988e-01],\n",
       "         [ 7.3332e-02, -3.4582e-01, -5.6562e-04,  ..., -8.6038e-01,\n",
       "           4.8961e-01, -7.9107e-01],\n",
       "         ...,\n",
       "         [-6.8505e-01,  6.0905e-04, -2.2925e-02,  ..., -3.6865e-02,\n",
       "           9.9722e-01,  1.6132e-01],\n",
       "         [-1.9446e-01, -2.7448e-01,  7.4617e-01,  ...,  7.7925e-02,\n",
       "           7.3011e-01, -2.0006e-01],\n",
       "         [-1.8238e-01, -2.3939e-01,  4.7600e-01,  ..., -1.2340e-01,\n",
       "           2.2728e-01, -7.3644e-03]]),\n",
       " tensor([5, 5, 2,  ..., 9, 6, 7]),\n",
       " torch.Size([52500, 10000]),\n",
       " torch.Size([52500]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_ = h[:cut]\n",
    "y_ = y[:cut]\n",
    "h_, y_, h_.shape, y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4bef5d-81e9-4d88-a29e-fe49b6d988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.zeros(10, 10000) #(classes, dim)\n",
    "\n",
    "for lbl in range(classes):\n",
    "    model2[lbl].add_(h_[y_ == lbl].sum(0), alpha=0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e997ea-8f48-4589-8a49-236903cd7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "banned = torch.arange(cut, device = h.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b042efbf-8f26-4565-8196-52b3fe35f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = h.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37bb93a2-1195-4b65-aba2-06b5bf2f6a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo = torch.ones(n, dtype=torch.bool, device=h.device)\n",
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c8136c8-b459-4134-8158-6b3fa01ea4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo[banned] = False\n",
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d83089bd-8d28-4c19-8f77-65c59c4afaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], size=(0, 10000)),\n",
       " tensor([], dtype=torch.int64),\n",
       " torch.Size([0, 10000]),\n",
       " torch.Size([0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_ = h[todo]\n",
    "y_ = y[todo]\n",
    "h_, y_, h_.shape, y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "006e9be0-4ff2-44e1-90b9-0bac6e1ec7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from onlinehd.onlinehd import _fasthd\n",
    "\n",
    "_fasthd.onepass(h_, y_, model2, 0.035).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f57187-c7a1-4a94-ab8f-8efe99a37a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will accumulate data from 0 to cut\n",
    "cut = math.ceil(bootstrap * h.size(0)) # 52500 data_count\n",
    "h_ = h[:cut]\n",
    "y_ = y[:cut]\n",
    "# updates each class hypervector (accumulating h_)\n",
    "\n",
    "for lbl in range(self.classes):\n",
    "    self.model[lbl].add_(h_[y_ == lbl].sum(0), alpha=lr)\n",
    "# banned will store already seen data to avoid using it later\n",
    "banned = torch.arange(cut, device=h.device)\n",
    "\n",
    "# todo will store not used before data\n",
    "n = h.size(0)\n",
    "todo = torch.ones(n, dtype=torch.bool, device=h.device)\n",
    "todo[banned] = False\n",
    "\n",
    "# will execute one pass learning with data not used during model\n",
    "# bootstrap\n",
    "h_ = h[todo]\n",
    "y_ = y[todo]\n",
    "_fasthd.onepass(h_, y_, self.model, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1acb58-f146-4e4a-adc0-1eb3ce516290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], size=(0, 10000)),\n",
       " tensor([], dtype=torch.int64),\n",
       " tensor([[ -28.3756,  -66.4885,   71.2560,  ...,  -49.9151,  114.5221,\n",
       "            -3.3383],\n",
       "         [ -29.8483, -134.8740,   58.2746,  ...,  -72.6994,   70.4318,\n",
       "           -29.3760],\n",
       "         [ -32.5078,  -91.7680,   34.5390,  ...,  -53.5381,  102.0280,\n",
       "           -47.4764],\n",
       "         ...,\n",
       "         [ -37.9302,  -80.4323,   62.0434,  ...,  -88.7540,   79.9782,\n",
       "           -74.9506],\n",
       "         [ -23.0486, -106.0506,   78.0832,  ...,  -87.1586,  107.0812,\n",
       "           -66.6282],\n",
       "         [ -38.9152,  -86.9536,   73.6600,  ..., -105.1869,   87.9439,\n",
       "           -72.4514]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_, y_, model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35395c-256c-4000-b04c-7792f00a2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_pass_fit(self, h, y, lr, bootstrap):\n",
    "    # initialize class hypervectors from a single datapoint\n",
    "    if bootstrap == 'single-per-class':\n",
    "        # get binary mask containing whether one datapoint belongs to each\n",
    "        # class\n",
    "        idxs = y == torch.arange(self.classes, device=h.device).unsqueeze_(1)\n",
    "        # choses first datapoint for every class\n",
    "        # banned will store already seen data to avoid using it later\n",
    "        banned = idxs.byte().argmax(1)\n",
    "        self.model.add_(h[banned].sum(0), alpha=lr)\n",
    "    else:\n",
    "        # will accumulate data from 0 to cut\n",
    "        cut = math.ceil(bootstrap*h.size(0))\n",
    "        h_ = h[:cut]\n",
    "        y_ = y[:cut]\n",
    "        # updates each class hypervector (accumulating h_)\n",
    "        for lbl in range(self.classes):\n",
    "            self.model[lbl].add_(h_[y_ == lbl].sum(0), alpha=lr)\n",
    "        # banned will store already seen data to avoid using it later\n",
    "        banned = torch.arange(cut, device=h.device)\n",
    "\n",
    "    # todo will store not used before data\n",
    "    n = h.size(0)\n",
    "    todo = torch.ones(n, dtype=torch.bool, device=h.device)\n",
    "    todo[banned] = False\n",
    "\n",
    "    # will execute one pass learning with data not used during model\n",
    "    # bootstrap\n",
    "    h_ = h[todo]\n",
    "    y_ = y[todo]\n",
    "    _fasthd.onepass(h_, y_, self.model, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d70b7-6a09-4555-82b9-63610db9b014",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebbc3577-580b-4a77-8bd6-1203dc0b895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, features : int, dim : int = 4000):\n",
    "    self.dim = dim\n",
    "    self.features = features\n",
    "    self.basis = torch.randn(self.dim, self.features)\n",
    "    self.base = torch.empty(self.dim).uniform_(0.0, 2*math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "008ff426-e09b-4187-b8c1-86bd5a761262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]),\n",
       " tensor([[ 0.5978,  0.8001,  0.5106,  ..., -0.3147,  0.0206,  0.8152],\n",
       "         [-0.9594,  0.0663,  0.2283,  ..., -0.9433, -0.1438, -0.0430],\n",
       "         [ 1.9078,  0.4669,  2.0367,  ...,  0.1945, -0.9101,  1.5179],\n",
       "         ...,\n",
       "         [-0.1508, -1.3020,  0.0563,  ..., -0.4242,  0.1127, -0.2668],\n",
       "         [-0.0116,  0.2193,  0.1171,  ..., -0.3250,  2.3068,  0.5962],\n",
       "         [-0.0846,  0.2933, -0.1665,  ..., -0.9736,  0.2808, -0.4440]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis = torch.randn(10000, 784)\n",
    "basis.shape, basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76e9aa8d-4bf1-4581-9e62-7c6a5fed4e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000]),\n",
       " tensor([1.3664, 5.7113, 0.8909,  ..., 0.5584, 4.6792, 4.7420]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = torch.empty(10000).uniform_(0.0, 2 * math.pi)\n",
    "base.shape, base\n",
    "\n",
    "# base`s range is 0~2*pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f74010-b828-42e9-b0c5-16199410f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __call__(self, x:torch.Tensor):\n",
    "    \n",
    "    n = x.size(0)\n",
    "    bsize = math.ceil(0.01*n)\n",
    "    h = torch.empty(n, self.dim, device=x.device, dtype=x.dtype)\n",
    "    temp = torch.empty(bsize, self.dim, device=x.device, dtype=x.dtype)\n",
    "\n",
    "    # we need batches to remove memory usage\n",
    "    for i in range(0, n, bsize):\n",
    "        torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
    "        torch.add(temp, self.base, out=h[i:i+bsize])\n",
    "        h[i:i+bsize].cos_().mul_(temp.sin_())\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e96ce2a-428b-4e4f-86ea-2552ec782ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52500, 525)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = data size\n",
    "n = x.size(0)\n",
    "bsize = math.ceil(0.01*n)\n",
    "n, bsize # batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e899121c-44c8-4bd3-a27e-91ca273683fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([52500, 10000]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.empty(n, 10000, device=x.device, dtype=x.dtype)\n",
    "h, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bfd70f9-dc6e-46b2-a7e1-4cd2bd720321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([525, 10000]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.empty(bsize, 10000, device=x.device, dtype=x.dtype)\n",
    "temp, temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac53f79-d27e-490b-a3d8-41496e7b653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need batches to remove memory usage\n",
    "for i in range(0, n, bsize):\n",
    "    torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
    "    torch.add(temp, self.base, out=h[i:i+bsize])\n",
    "#    h[i:i+bsize].cos_().mul_(temp.sin_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55d6da34-5718-4d38-af94-b0825b4e7dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([525, 784]), torch.Size([784, 10000]), torch.Size([525, 10000]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:525].shape, basis.T.shape, temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a997680-2fe0-4072-b36b-20f14cf48ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([525, 10000]),\n",
       " tensor([[-1.9109,  0.1523,  1.0126,  ...,  0.5885, -1.7621, -0.6240],\n",
       "         [-2.7255, -0.2020,  0.3480,  ...,  0.1416, -0.2177, -0.5781],\n",
       "         [-0.5035, -0.1305,  0.3695,  ...,  0.1198, -0.4447,  0.1681],\n",
       "         ...,\n",
       "         [-1.3973,  1.2775,  0.8775,  ...,  0.0473,  0.0674, -0.8231],\n",
       "         [-1.2422,  1.1375, -0.0432,  ..., -0.3398,  0.5718, -0.4027],\n",
       "         [-3.6735, -0.9208, -0.9681,  ..., -1.4667, -1.2538, -0.2241]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x[0:525], basis.T, out=temp)\n",
    "temp.shape, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6704ae6e-e2f0-468d-82e8-265f0e1fae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000]),\n",
       " tensor([1.3664, 5.7113, 0.8909,  ..., 0.5584, 4.6792, 4.7420]),\n",
       " torch.Size([52500, 10000]),\n",
       " tensor([[-0.5446,  5.8636,  1.9035,  ...,  1.1468,  2.9171,  4.1180],\n",
       "         [-1.3592,  5.5093,  1.2390,  ...,  0.7000,  4.4616,  4.1640],\n",
       "         [ 0.8628,  5.5807,  1.2604,  ...,  0.6782,  4.2345,  4.9102],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(temp, base, out=h[0:525])\n",
    "base.shape, base, h.shape, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd936e7d-04eb-4d70-a25d-a3d1dd73c51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5446,  5.8636,  1.9035,  ...,  1.1468,  2.9171,  4.1180],\n",
       "        [-1.3592,  5.5093,  1.2390,  ...,  0.7000,  4.4616,  4.1640],\n",
       "        [ 0.8628,  5.5807,  1.2604,  ...,  0.6782,  4.2345,  4.9102],\n",
       "        ...,\n",
       "        [-0.0309,  6.9888,  1.7685,  ...,  0.6057,  4.7466,  3.9190],\n",
       "        [ 0.1242,  6.8488,  0.8478,  ...,  0.2186,  5.2510,  4.3393],\n",
       "        [-2.3071,  4.7905, -0.0772,  ..., -0.9083,  3.4255,  4.5180]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0:525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3721eeae-450a-4ac6-b4b3-8f8897bcf246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8554,  0.9132, -0.3266,  ...,  0.4114, -0.9749, -0.5600],\n",
       "        [ 0.2101,  0.7152,  0.3258,  ...,  0.7649, -0.2482, -0.5214],\n",
       "        [ 0.6503,  0.7633,  0.3054,  ...,  0.7787, -0.4599,  0.1965],\n",
       "        ...,\n",
       "        [ 0.9995,  0.7612, -0.1964,  ...,  0.8221,  0.0342, -0.7128],\n",
       "        [ 0.9923,  0.8443,  0.6616,  ...,  0.9762,  0.5130, -0.3645],\n",
       "        [-0.6716,  0.0780,  0.9970,  ...,  0.6151, -0.9600, -0.1932]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0:525].cos_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "659dfef7-8bc5-4f42-85e5-44e0ffce8f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5444737304601713"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.acos(0.8554)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1c880-d190-4e37-b815-03bcc3d7f7f3",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50daf40-6836-4c5a-94db-184dfdad40fe",
   "metadata": {},
   "source": [
    "h[i:i+bsize].cos_().mul_(temp.sin_())\n",
    "\n",
    "torch.add(temp, self.base, out=h[i:i+bsize])\n",
    "\n",
    "torch.matmul(x[i:i+bsize], self.basis.T, out=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e26e88f-cf79-407e-bbf5-f68c547674bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5446, 0.4196, 1.9035,  ..., 1.1468, 2.9171, 2.1651],\n",
       "        [1.3592, 0.7739, 1.2390,  ..., 0.7000, 1.8216, 2.1192],\n",
       "        [0.8628, 0.7024, 1.2604,  ..., 0.6782, 2.0487, 1.3730],\n",
       "        ...,\n",
       "        [0.0309, 0.7056, 1.7685,  ..., 0.6057, 1.5366, 2.3642],\n",
       "        [0.1242, 0.5656, 0.8478,  ..., 0.2186, 1.0322, 1.9439],\n",
       "        [2.3071, 1.4927, 0.0772,  ..., 0.9083, 2.8577, 1.7652]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0:525].acos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5269a5-c179-4f27-8eec-77a6a3263f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ce256-e420-4780-8d1f-a4711eeb0311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCI",
   "language": "python",
   "name": "uci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
